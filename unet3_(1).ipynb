{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csVd9Zxt21d5",
        "outputId": "b4e7702d-eae6-4d3d-d66d-0b81451d34b9"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch_lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6s33qacFYox",
        "outputId": "ad705eaa-4126-43be-d483-da7f20dd7dbb"
      },
      "outputs": [],
      "source": [
        "!pip install torchtext==0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LR-VfJSLiqj",
        "outputId": "238e4b92-12f4-4555-ed3e-74bda0474afa"
      },
      "outputs": [],
      "source": [
        "pip install torchmetrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALnX2uoxFjWd",
        "outputId": "e7d966cd-626b-4cca-e73d-7a86d652f22e"
      },
      "outputs": [],
      "source": [
        "pip install celluloid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tjx1YHe63Adp"
      },
      "outputs": [],
      "source": [
        "%matplotlib notebook\n",
        "from pathlib import Path\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from celluloid import Camera\n",
        "from tqdm.notebook import tqdm\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qR6FpHK4SuK",
        "outputId": "e04e112d-742f-483a-a0ab-380688674e1e"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\",force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWjbrv6Iz28y"
      },
      "outputs": [],
      "source": [
        "def change_img_to_label_path(path):\n",
        "    \"\"\"\n",
        "    Replaces imagesTr with labelsTr\n",
        "    \"\"\"\n",
        "    parts = list(path.parts)  # get all directories whithin the path\n",
        "    parts[parts.index(\"imagesTr\")] = \"labelsTr\"  # Replace imagesTr with labelsTr\n",
        "    return Path(*parts)  # Combine list back into a Path object\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "tUEhIxodz6YJ",
        "outputId": "3d21dc31-b721-4842-e532-c8c6e616de59"
      },
      "outputs": [],
      "source": [
        "# Inspect some sample data\n",
        "root = Path(\"/content/drive/MyDrive/ML/Task06_Lung/Task06_Lung/imagesTr\")\n",
        "label = Path(\"/content/drive/MyDrive/ML/Task06_Lung/Task06_Lung/labelsTr/\")\n",
        "\n",
        "lung_paths = list(root.glob(\"lung*\"))\n",
        "print(\"Number of lung paths:\", len(lung_paths))\n",
        "\n",
        "\n",
        "sample_path = list(root.glob(\"lung*\"))[9]  # Choose a subject\n",
        "sample_path_label = change_img_to_label_path(sample_path)\n",
        "\n",
        "print(sample_path)\n",
        "print(sample_path_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "-oChJOWi0JGb",
        "outputId": "6a8431aa-2e68-49dc-f4a5-bdf280829307"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load NIfTI and extract image data\n",
        "data = nib.load(sample_path)\n",
        "label = nib.load(sample_path_label)\n",
        "\n",
        "ct = data.get_fdata()\n",
        "mask = label.get_fdata()\n",
        "\n",
        "print(mask.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "pB6Gtt8e0RcB",
        "outputId": "8d7c1ae2-6fb3-4e1d-f074-0f8aec74b2ac"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Find out the orientation\n",
        "nib.aff2axcodes(data.affine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "FPCIm3e-0WJp",
        "outputId": "4d5c67cb-c999-4bd1-a4a5-a93258242d29"
      },
      "outputs": [],
      "source": [
        "root = Path(\"/content/drive/MyDrive/ML/Task06_Lung/Task06_Lung/imagesTr\")\n",
        "label = Path(\"/content/drive/MyDrive/ML/Task06_Lung/Task06_Lung/labelsTr/\")\n",
        "\n",
        "all_files = list(root.glob(\"lung_*\"))  # Get all subjects\n",
        "all_files.sort()\n",
        "\n",
        "print(all_files[3])\n",
        "print(len(all_files))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZO3v8ad10Z_b"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create train directories for saving images and masks\n",
        "\n",
        "save_root = Path(\"/content/drive/MyDrive/Preprocessed\")\n",
        "\n",
        "train_slice_path = save_root/\"train\"/\"data\"\n",
        "train_mask_path = save_root/\"train\"/\"masks\"\n",
        "\n",
        "train_slice_path.mkdir(parents=True, exist_ok=True)\n",
        "train_mask_path.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "wrqGHJ1G0xIG",
        "outputId": "ee201752-8839-45d2-c0be-1f55b1ef8fc4"
      },
      "outputs": [],
      "source": [
        "all_data = []\n",
        "all_lables = []\n",
        "\n",
        "counter = 0 # for naming files\n",
        "\n",
        "for _ , path_to_ct_data in enumerate(tqdm(all_files)):\n",
        "\n",
        "    path_to_label = change_img_to_label_path(path_to_ct_data)  # Get path to ground truth\n",
        "\n",
        "    # Load and extract corresponding data\n",
        "    ct_data = nib.load(path_to_ct_data).get_fdata()\n",
        "    label_data = nib.load(path_to_label).get_fdata()\n",
        "\n",
        "    # Crop volume and label. Remove the first 30 slices\n",
        "    ct_data = ct_data[:,:,30:] / 3071\n",
        "    new_label_data = label_data[:,:,30:]\n",
        "\n",
        "    # Loop over the slices in the full volume and store the data and labels in the data/masks directory\n",
        "    # Save all filenames in all_data and whether it has tumor or not in all_lables\n",
        "    for i in range(ct_data.shape[-1]):\n",
        "        slice = ct_data[:,:,i]\n",
        "        mask = new_label_data[:,:,i]\n",
        "\n",
        "        # Resize slice and label to common resolution to reduce training time\n",
        "        slice = cv2.resize(slice, (256, 256))\n",
        "        mask = cv2.resize(mask, (256, 256), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        # Generate name of slice and its corresponding mask\n",
        "        slice_name = f'slice_000000{100000+counter}'\n",
        "        mask_name = f'mask_000000{100000+counter}'\n",
        "\n",
        "        # Save filenames and classification label of slice in for train_test spliting later\n",
        "        all_data.append(np.array([slice_name,mask_name]))\n",
        "        all_lables.append(mask.any())\n",
        "\n",
        "        counter += 1\n",
        "        np.save(train_slice_path/slice_name, slice, allow_pickle=True)\n",
        "        np.save(train_mask_path/mask_name, mask, allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "R_a8Kht102CJ",
        "outputId": "b0fb3f7b-99a2-43a2-c732-c6a5402a39b2"
      },
      "outputs": [],
      "source": [
        "all_data_np = np.array(all_data)\n",
        "all_lables_np = np.array(all_lables)\n",
        "\n",
        "print(all_data_np.shape)\n",
        "print(all_lables_np.shape)\n",
        "\n",
        "# This shows distribution of classification label (number of non-tumor slices vs. tumor slices).\n",
        "print(np.unique(all_lables_np, return_counts=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "aD4hC-En03VY",
        "outputId": "d5651c3b-20a1-4ae5-b9e0-a4b5d1517658"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting data to train and test\n",
        "# If we activate stratify as input, the train and test datasets will have same\n",
        "# distribution for tumor slices.\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                all_data_np,\n",
        "                all_lables_np,\n",
        "                test_size=0.2,\n",
        "                random_state=13,\n",
        "                stratify = all_lables_np,\n",
        "                )\n",
        "\n",
        "print(\"Shape of training set:\", X_train.shape)\n",
        "print(\"Shape of test set:\", X_test.shape)\n",
        "\n",
        "print(np.unique(y_train, return_counts=True))\n",
        "print(np.unique(y_test, return_counts=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saOsMaKb09Yu"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Now that we know which slices belong to validation we can move them in their own directory\n",
        "\n",
        "val_slice_path = save_root/\"val\"/\"data\"\n",
        "val_mask_path = save_root/\"val\"/\"masks\"\n",
        "\n",
        "val_slice_path.mkdir(parents=True, exist_ok=True)\n",
        "val_mask_path.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hOjqoA61Ei9"
      },
      "outputs": [],
      "source": [
        "\n",
        "for test in X_test:\n",
        "    Path(rf'{train_slice_path}/{test[0]}.npy').replace(rf'{val_slice_path}/{test[0]}.npy')\n",
        "    Path(rf'{train_mask_path}/{test[1]}.npy').replace(rf'{val_mask_path}/{test[1]}.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "1DJZxds01LvO",
        "outputId": "cb0060af-d01c-4c63-f644-4d9a3a79693f"
      },
      "outputs": [],
      "source": [
        "tumor_slice_idxs = []\n",
        "for i in range (y_test.shape[0]):\n",
        "    if y_test[i]:\n",
        "        tumor_slice_idxs.append(i)\n",
        "\n",
        "print(tumor_slice_idxs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "M4p0Wajf1Ms2",
        "outputId": "23e33d3f-9e4c-4f9e-b54d-33e11f3fa82b"
      },
      "outputs": [],
      "source": [
        "test = X_test[2683]\n",
        "\n",
        "slice_path = Path(val_slice_path/test[0])\n",
        "mask_path = Path(val_mask_path/test[1])\n",
        "\n",
        "# Choose a file and load slice + mask\n",
        "slice = np.load(str(slice_path) + '.npy')\n",
        "mask = np.load(str(mask_path) + '.npy')\n",
        "\n",
        "print(slice.shape)\n",
        "print(slice.min(), slice.max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "id": "RNaRXb051TH9",
        "outputId": "559ef2b7-2fda-4f46-e4c1-01d417d88442"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "fig, axis = plt.subplots(1, 2, figsize=(8, 8))\n",
        "axis[0].imshow(slice, cmap=\"bone\")\n",
        "mask_ = np.ma.masked_where(mask==0, mask)\n",
        "axis[1].imshow(slice, cmap=\"bone\")\n",
        "axis[1].imshow(mask_, cmap=\"autumn\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wvm53_ol1fhj"
      },
      "outputs": [],
      "source": [
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "import imgaug\n",
        "import imgaug.augmenters as iaa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "from celluloid import Camera\n",
        "from imgaug.augmentables.segmaps import SegmentationMapsOnImage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3buUpMh-HdS"
      },
      "outputs": [],
      "source": [
        "class LungDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, augment_params):\n",
        "        self.all_files = self.extract_files(root)\n",
        "        self.augment_params = augment_params\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_files(root):\n",
        "        \"\"\"\n",
        "        Extract the paths to all slices given the root path (ends with train or val)\n",
        "        \"\"\"\n",
        "        files = []\n",
        "        slice_path = root/\"data\"  # Get the slices for current subject\n",
        "        for slice in slice_path.glob(\"*\"):\n",
        "            files.append(slice)\n",
        "        return files\n",
        "\n",
        "    @staticmethod\n",
        "    def change_img_to_label_path(path):\n",
        "        \"\"\"\n",
        "        Replace data with mask to get the masks\n",
        "        \"\"\"\n",
        "        parts = list(path.parts)\n",
        "        parts[-2] = \"masks\"\n",
        "        parts[-1] = parts[-1].replace('slice','mask')\n",
        "        return Path(*parts)\n",
        "\n",
        "    def augment(self, slice, mask):\n",
        "        \"\"\"\n",
        "        Augments slice and segmentation mask in the exact same way\n",
        "        Note the manual seed initialization\n",
        "        \"\"\"\n",
        "        ###################IMPORTANT###################\n",
        "        random_seed = torch.randint(0, 1000000, (1,))[0].item()\n",
        "        imgaug.seed(random_seed)\n",
        "        #####################################################\n",
        "\n",
        "        new_mask = mask.astype(bool)\n",
        "\n",
        "        mask = SegmentationMapsOnImage(new_mask, new_mask.shape)\n",
        "        slice_aug, mask_aug = self.augment_params(image=slice, segmentation_maps=mask)\n",
        "        mask_aug = mask_aug.get_arr()\n",
        "        return slice_aug, mask_aug\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Return the length of the dataset (length of all files)\n",
        "        \"\"\"\n",
        "        return len(self.all_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Given an index return the (augmented) slice and corresponding mask\n",
        "        Add another dimension for pytorch\n",
        "        \"\"\"\n",
        "        file_path = self.all_files[idx]\n",
        "        mask_path = self.change_img_to_label_path(file_path)\n",
        "        slice = np.load(file_path)\n",
        "        mask = np.load(mask_path)\n",
        "\n",
        "        if self.augment_params:\n",
        "            slice, mask = self.augment(slice, mask)\n",
        "        return np.expand_dims(slice, 0), np.expand_dims(mask, 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31iNg9J2-YDB"
      },
      "outputs": [],
      "source": [
        "import imgaug.augmenters as iaa\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Affine(translate_percent=(0.15),\n",
        "               scale=(0.85, 1.15), # zoom in or out\n",
        "               rotate=(-45, 45)#\n",
        "               ),  # rotate up to 45 degrees\n",
        "    iaa.ElasticTransformation()  # Elastic Transformations\n",
        "                ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBsBDO7qGH1p",
        "outputId": "f170bfc2-4526-42ea-8266-bba6ff8a2587"
      },
      "outputs": [],
      "source": [
        "# Create the dataset objects\n",
        "train_path = Path(\"/content/drive/MyDrive/Preprocessed/train\")\n",
        "val_path = Path(\"/content/drive/MyDrive/Preprocessed/val\")\n",
        "\n",
        "train_dataset = LungDataset(train_path, seq)\n",
        "val_dataset = LungDataset(val_path, None)\n",
        "\n",
        "print(f\"There are {len(train_dataset)} train images and {len(val_dataset)} val images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a91b2dcf317d4fbe820512d900cfb544",
            "21274716d10f477997dbef92740085a1",
            "ede48dc6ffd142cbb57961a05107791e",
            "6a75762fef434e59944f41cfe143efd5",
            "75f3c47062b1495397b342840a1eb93e",
            "79a9540eb71b468ab1c53630ba8977da",
            "335582be7b2744f297d283cd6f325be7",
            "0ead6ecd104745778662c5f161e75b8d",
            "23717510d68d4737b9c7a202cfd026ee",
            "efad95892b794921b902af453798ec63",
            "e75a4d0d1ec94df0be71b3b946b447d0"
          ]
        },
        "id": "SWnY5_77f_aI",
        "outputId": "88e5913a-a38c-42b0-c923-cb0e0d35d089"
      },
      "outputs": [],
      "source": [
        "target_list = []\n",
        "\n",
        "for _, label in tqdm(train_dataset):\n",
        "    # Check if mask contains a tumorous pixel:\n",
        "    if np.any(label):\n",
        "        target_list.append(1)\n",
        "    else:\n",
        "        target_list.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxCShChh7wIw",
        "outputId": "346e2211-dc3a-47a8-eb08-3e18ba07ae15"
      },
      "outputs": [],
      "source": [
        "# Calculate the weight for each class\n",
        "uniques = np.unique(target_list, return_counts=True)\n",
        "print(\"Class distribution:\", uniques)\n",
        "\n",
        "# Calculate the fraction (class imbalance ratio)\n",
        "fraction = uniques[1][0] / uniques[1][1]\n",
        "print(\"Class imbalance ratio:\", fraction)\n",
        "\n",
        "# Calculate weights\n",
        "weights = [1.0, fraction]\n",
        "\n",
        "print(\"Class weights:\", weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPasdi847w_1",
        "outputId": "5ef3906e-0b99-4151-ffa8-ffe54ab2365c"
      },
      "outputs": [],
      "source": [
        "# Create a list of weights based on the class labels\n",
        "weight_list = [1.0 if target == 0 else fraction for target in target_list]\n",
        "\n",
        "# Print the first 50 weights as an example\n",
        "print(\"Example of weights:\", weight_list[50:])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFlfYJhrgn8Y"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# Select only the first 2000 samples\n",
        "selected_indices = range(2000)\n",
        "\n",
        "# Create a list of weights based on the class labels for the selected samples\n",
        "selected_weight_list = [weight_list[i] for i in selected_indices]\n",
        "\n",
        "# Create the sampler for the selected samples\n",
        "sampler = torch.utils.data.sampler.WeightedRandomSampler(selected_weight_list, len(selected_weight_list))\n",
        "\n",
        "# Assuming your DataLoader is named 'train_loader'\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=8, sampler=sampler, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4uEEef6gumO"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Subset\n",
        "batch_size = 8\n",
        "num_workers = 2\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                           num_workers=num_workers, sampler=sampler)\n",
        "subset_indices = range(300)  # Adjust this range based on your requirement\n",
        "\n",
        "subset_val_dataset = Subset(val_dataset, subset_indices)\n",
        "val_loader = torch.utils.data.DataLoader(subset_val_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5ioUgkfg1fl",
        "outputId": "4ac078f3-5ce5-4467-8589-5ce584e65455"
      },
      "outputs": [],
      "source": [
        "# We can verify that our sampler works by taking a batch from the train loader and count how many labels are larger than zero\n",
        "verify_batch = next(iter(train_loader))  # Take one batch\n",
        "\n",
        "# Assuming your labels are in the second element of the batch (modify if needed)\n",
        "labels_in_batch = verify_batch[1]\n",
        "\n",
        "# Count how many labels are larger than zero\n",
        "count_positive_labels = (labels_in_batch > 0).sum().item()\n",
        "\n",
        "print(f\"Number of labels larger than zero: {count_positive_labels}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zbz8q2yYg3y4",
        "outputId": "1644b9f4-6192-43f4-d9ee-2a5c68f9db16"
      },
      "outputs": [],
      "source": [
        "# Print the shape of the labels in the verification batch\n",
        "print(verify_sampler[1].shape)\n",
        "\n",
        "# Check if any tumorous pixel is present in each label\n",
        "verify_labels = np.any(np.array(verify_sampler[1]), axis=(1, 2, 3))\n",
        "print(verify_labels)\n",
        "\n",
        "# Extract and print the shape of a slice and its corresponding mask from the batch\n",
        "slice = verify_sampler[0][1].squeeze()\n",
        "mask = verify_sampler[1][1].squeeze()\n",
        "print(slice.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqqcIcddEhGt",
        "outputId": "9bf79085-1289-4a40-d32d-96287f62da02"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import init\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "        return x\n",
        "\n",
        "class UNet_3PlusModified(nn.Module):\n",
        "    def __init__(self, in_channels=1, n_classes=1, feature_scale=4, is_deconv=True, is_batchnorm=True):\n",
        "        super(UNet_3PlusModified, self).__init__()\n",
        "        self.is_deconv = is_deconv\n",
        "        self.in_channels = in_channels\n",
        "        self.is_batchnorm = is_batchnorm\n",
        "        self.feature_scale = feature_scale\n",
        "\n",
        "        filters = [64, 128, 256, 512, 1024]\n",
        "\n",
        "        # Encoder\n",
        "        self.conv1 = DoubleConv(in_channels, filters[0])\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.conv2 = DoubleConv(filters[0], filters[1])\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.conv3 = DoubleConv(filters[1], filters[2])\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.conv4 = DoubleConv(filters[2], filters[3])\n",
        "        self.maxpool4 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.conv5 = DoubleConv(filters[3], filters[4])\n",
        "\n",
        "        # Decoder\n",
        "        self.CatChannels = filters[0]\n",
        "        self.CatBlocks = 5\n",
        "        self.UpChannels = self.CatChannels * self.CatBlocks\n",
        "\n",
        "        self.hd5_UT_hd4 = nn.Upsample(scale_factor=2, mode='bilinear')\n",
        "        self.hd5_UT_hd4_conv = DoubleConv(filters[4], self.CatChannels)\n",
        "\n",
        "        self.conv4d_1 = DoubleConv(self.UpChannels, self.UpChannels)\n",
        "\n",
        "        self.hd5_UT_hd3 = nn.Upsample(scale_factor=4, mode='bilinear')\n",
        "        self.hd5_UT_hd3_conv = DoubleConv(filters[4], self.CatChannels)\n",
        "\n",
        "        self.conv3d_1 = DoubleConv(self.UpChannels, self.UpChannels)\n",
        "\n",
        "        self.hd5_UT_hd2 = nn.Upsample(scale_factor=8, mode='bilinear')\n",
        "        self.hd5_UT_hd2_conv = DoubleConv(filters[4], self.CatChannels)\n",
        "\n",
        "        self.conv2d_1 = DoubleConv(self.UpChannels, self.UpChannels)\n",
        "\n",
        "        self.hd5_UT_hd1 = nn.Upsample(scale_factor=16, mode='bilinear')\n",
        "        self.hd5_UT_hd1_conv = DoubleConv(filters[4], self.CatChannels)\n",
        "\n",
        "        self.conv1d_1 = DoubleConv(self.UpChannels, self.UpChannels)\n",
        "\n",
        "        # Output\n",
        "        self.outconv1 = nn.Conv2d(self.UpChannels, n_classes, kernel_size=3, padding=1)\n",
        "\n",
        "        # Initialize weights\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                init_weights(m, init_type='kaiming')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                init_weights(m, init_type='kaiming')\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        inputs = inputs.float()\n",
        "\n",
        "        # Encoder\n",
        "        h1 = self.conv1(inputs)\n",
        "        h2 = self.maxpool1(h1)\n",
        "        h2 = self.conv2(h2)\n",
        "        h3 = self.maxpool2(h2)\n",
        "        h3 = self.conv3(h3)\n",
        "        h4 = self.maxpool3(h3)\n",
        "        h4 = self.conv4(h4)\n",
        "        h5 = self.maxpool4(h4)\n",
        "        hd5 = self.conv5(h5)\n",
        "\n",
        "        # Decoder\n",
        "        h1_PT_hd4 = self.hd5_UT_hd4_conv(self.hd5_UT_hd4(hd5))\n",
        "        h2_PT_hd4 = self.hd5_UT_hd4_conv(self.maxpool1(h1))\n",
        "        h3_PT_hd4 = self.hd5_UT_hd4_conv(self.maxpool2(h2))\n",
        "        h4_Cat_hd4 = self.hd5_UT_hd4_conv(self.maxpool3(h3))\n",
        "        h5_Cat_hd4 = self.hd5_UT_hd4_conv(h4)\n",
        "\n",
        "        hd4 = self.conv4d_1(torch.cat((h1_PT_hd4, h2_PT_hd4, h3_PT_hd4, h4_Cat_hd4, h5_Cat_hd4), 1))\n",
        "\n",
        "        h1_PT_hd3 = self.hd5_UT_hd3_conv(self.hd5_UT_hd3(hd5))\n",
        "        h2_PT_hd3 = self.hd5_UT_hd3_conv(self.maxpool1(h1))\n",
        "        h3_PT_hd3 = self.hd5_UT_hd3_conv(self.maxpool2(h2))\n",
        "        h4_PT_hd3 = self.hd5_UT_hd3_conv(self.maxpool3(h3))\n",
        "        h5_Cat_hd3 = self.hd5_UT_hd3_conv(h4)\n",
        "\n",
        "        hd3 = self.conv3d_1(torch.cat((h1_PT_hd3, h2_PT_hd3, h3_PT_hd3, h4_PT_hd3, h5_Cat_hd3), 1))\n",
        "\n",
        "        h1_PT_hd2 = self.hd5_UT_hd2_conv(self.hd5_UT_hd2(hd5))\n",
        "        h2_PT_hd2 = self.hd5_UT_hd2_conv(self.maxpool1(h1))\n",
        "        h3_PT_hd2 = self.hd5_UT_hd2_conv(self.maxpool2(h2))\n",
        "        h4_PT_hd2 = self.hd5_UT_hd2_conv(self.maxpool3(h3))\n",
        "        h5_PT_hd2 = self.hd5_UT_hd2_conv(self.maxpool4(h4))\n",
        "\n",
        "        hd2 = self.conv2d_1(torch.cat((h1_PT_hd2, h2_PT_hd2, h3_PT_hd2, h4_PT_hd2, h5_PT_hd2), 1))\n",
        "\n",
        "        h1_PT_hd1 = self.hd5_UT_hd1_conv(self.hd5_UT_hd1(hd5))\n",
        "        h2_PT_hd1 = self.hd5_UT_hd1_conv(self.maxpool1(h1))\n",
        "        h3_PT_hd1 = self.hd5_UT_hd1_conv(self.maxpool2(h2))\n",
        "        h4_PT_hd1 = self.hd5_UT_hd1_conv(self.maxpool3(h3))\n",
        "        h5_PT_hd1 = self.hd5_UT_hd1_conv(self.maxpool4(h4))\n",
        "\n",
        "        hd1 = self.conv1d_1(torch.cat((h1_PT_hd1, h2_PT_hd1, h3_PT_hd1, h4_PT_hd1, h5_PT_hd1), 1))\n",
        "\n",
        "        # Output\n",
        "        out = self.outconv1(hd1)\n",
        "\n",
        "        return out\n",
        "\n",
        "def init_weights(m, init_type='kaiming'):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        if init_type == 'kaiming':\n",
        "            init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        elif init_type == 'xavier':\n",
        "            init.xavier_normal_(m.weight)\n",
        "        elif init_type == 'orthogonal':\n",
        "            init.orthogonal_(m.weight)\n",
        "        else:\n",
        "            raise NotImplementedError(f'Initialization method {init_type} is not implemented')\n",
        "\n",
        "# Instantiate the model\n",
        "model = UNet_3PlusModified()\n",
        "\n",
        "# Print the model architecture\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "Kzz2aDJ7hayU",
        "outputId": "47e41d2b-a6ef-4d93-e973-81c0b70a949c"
      },
      "outputs": [],
      "source": [
        "# Full Segmentation Model\n",
        "class TumorSegmentation(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = UNet_3PlusModified()\n",
        "\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
        "        self.loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, data):\n",
        "        pred = self.model(data)\n",
        "        return pred\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        ct, mask = batch\n",
        "        mask = mask.float()\n",
        "        ct = ct.float()\n",
        "\n",
        "        pred = self(ct)\n",
        "        loss = self.loss_fn(pred, mask)\n",
        "\n",
        "        # Logs\n",
        "        self.log(\"Train Dice\", loss)\n",
        "        if batch_idx % 50 == 0:\n",
        "            self.log_images(ct.cpu(), pred.cpu(), mask.cpu(), \"Train\")\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        ct, mask = batch\n",
        "        mask = mask.float()\n",
        "        ct = ct.float()\n",
        "\n",
        "        pred = self(ct)\n",
        "        loss = self.loss_fn(pred, mask)\n",
        "\n",
        "        # Logs\n",
        "        self.log(\"Val Dice\", loss)\n",
        "        if batch_idx % 50 == 0:\n",
        "            self.log_images(ct.cpu(), pred.cpu(), mask.cpu(), \"Val\")\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def log_images(self, ct, pred, mask, name):\n",
        "\n",
        "        results = []\n",
        "\n",
        "        pred = pred > 0.5 # As we use the sigomid activation function, we threshold at 0.5\n",
        "\n",
        "\n",
        "        fig, axis = plt.subplots(1, 2)\n",
        "        axis[0].imshow(ct[0][0], cmap=\"bone\")\n",
        "        mask_ = np.ma.masked_where(mask[0][0]==0, mask[0][0])\n",
        "        axis[0].imshow(mask_, alpha=0.6)\n",
        "        axis[0].set_title(\"Ground Truth\")\n",
        "\n",
        "        axis[1].imshow(ct[0][0], cmap=\"bone\")\n",
        "        mask_ = np.ma.masked_where(pred[0][0]==0, pred[0][0])\n",
        "        axis[1].imshow(mask_, alpha=0.6, cmap=\"autumn\")\n",
        "        axis[1].set_title(\"Pred\")\n",
        "\n",
        "        self.logger.experiment.add_figure(f\"{name} Prediction vs Label\", fig, self.global_step)\n",
        "\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        #We always need to return a list here (just pack our optimizer into one :))\n",
        "        return [self.optimizer]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOrS7Q1GhuNr",
        "outputId": "d4af8596-33d0-4406-eb37-7b04be5a04f9"
      },
      "outputs": [],
      "source": [
        "# Instanciate the model\n",
        "model = TumorSegmentation()\n",
        "\n",
        "# Create the checkpoint callback\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor='Val Dice',\n",
        "    save_top_k=30,\n",
        "    mode='min')\n",
        "\n",
        "# Create the trainer\n",
        "trainer = pl.Trainer(accelerator=\"cuda\",\n",
        "                     logger=TensorBoardLogger(save_dir=\"/content/drive/MyDrive/output\"),\n",
        "                     log_every_n_steps=1,\n",
        "                     callbacks=checkpoint_callback,\n",
        "                     max_epochs=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyc2I-4UiOI5"
      },
      "outputs": [],
      "source": [
        "\n",
        "trainer.fit(model, train_loader, val_loader,\n",
        "            # ckpt_path = \"/content/drive/MyDrive/output/lightning_logs/version_1/checkpoints/epoch=20-step=33117.ckpt\"\n",
        "            )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDjoLg8qioG-"
      },
      "outputs": [],
      "source": [
        "class DiceScore(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    class to compute the Dice Loss\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, pred, mask):\n",
        "\n",
        "        #flatten label and prediction tensors\n",
        "        pred = torch.flatten(pred)\n",
        "        mask = torch.flatten(mask)\n",
        "\n",
        "        counter = (pred * mask).sum()  # Counter\n",
        "        denum = pred.sum() + mask.sum()  # denominator\n",
        "        dice = (2*counter)/denum\n",
        "\n",
        "        return dice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-2bJ_kIipDa"
      },
      "outputs": [],
      "source": [
        "model = TumorSegmentation.load_from_checkpoint(\"/content/drive/MyDrive/output/lightning_logs/version_0/checkpoints/epoch=0-step=404.ckpt\",\n",
        "                                               map_location=torch.device('cpu'))\n",
        "model.eval();\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ie7iY1kgisGT",
        "outputId": "0ceaa6a9-fbc9-4841-e442-db29690a3bbc"
      },
      "outputs": [],
      "source": [
        "\n",
        "preds = []\n",
        "labels = []\n",
        "\n",
        "for slice, label in tqdm(val_dataset):\n",
        "    slice = torch.tensor(slice).float().to(device).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        pred = torch.sigmoid(model(slice))\n",
        "    preds.append(pred.cpu().numpy())\n",
        "    labels.append(label)\n",
        "\n",
        "preds = np.array(preds)\n",
        "labels = np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_ZdNy_ZivLu",
        "outputId": "a555f836-5dee-4942-9b31-bd0fac3c98e9"
      },
      "outputs": [],
      "source": [
        "dice_score = DiceScore()(torch.from_numpy(preds), torch.from_numpy(labels).unsqueeze(0).float())\n",
        "print(f\"The Val Dice Score is: {dice_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mFIZw3Oyi_g"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ead6ecd104745778662c5f161e75b8d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21274716d10f477997dbef92740085a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79a9540eb71b468ab1c53630ba8977da",
            "placeholder": "​",
            "style": "IPY_MODEL_335582be7b2744f297d283cd6f325be7",
            "value": "  1%"
          }
        },
        "23717510d68d4737b9c7a202cfd026ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "335582be7b2744f297d283cd6f325be7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a75762fef434e59944f41cfe143efd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efad95892b794921b902af453798ec63",
            "placeholder": "​",
            "style": "IPY_MODEL_e75a4d0d1ec94df0be71b3b946b447d0",
            "value": " 120/12058 [01:01&lt;1:38:08,  2.03it/s]"
          }
        },
        "75f3c47062b1495397b342840a1eb93e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79a9540eb71b468ab1c53630ba8977da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a91b2dcf317d4fbe820512d900cfb544": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21274716d10f477997dbef92740085a1",
              "IPY_MODEL_ede48dc6ffd142cbb57961a05107791e",
              "IPY_MODEL_6a75762fef434e59944f41cfe143efd5"
            ],
            "layout": "IPY_MODEL_75f3c47062b1495397b342840a1eb93e"
          }
        },
        "e75a4d0d1ec94df0be71b3b946b447d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ede48dc6ffd142cbb57961a05107791e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ead6ecd104745778662c5f161e75b8d",
            "max": 12058,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23717510d68d4737b9c7a202cfd026ee",
            "value": 120
          }
        },
        "efad95892b794921b902af453798ec63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
